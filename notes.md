# MUSA509 Final Project scratch pad

1. Develop scripts to extract data from sources and load into PostgreSQL and/or BigQuery
2. Create the structure for your Airflow pipeline and add your extract/load scripts to it
3. Deploy your pipeline to a cloud server (and document your deployment steps for when -- not if -- you forget them)
4. Dive deeper into data
5. Experiment and develop queries for metrics, using tools such as PGAdmin, BigQuery, or Jupyter Notebooks
6. Note useful data transformations and queries
7. Convert explorations into SQL and Python scripts to transform ingested data
8. Experiment with visualizations of metrics
9. Create "live mockup(s)" in HTML of dashboard page(s)
10. Configure a GCS
11. Convert mockup(s) to template(s)
12. Create scripts to render template(s) for dashboard page(s)


https://github.com/musa-509-fall-2021/final-project-sample/blob/main/airflow/plugins/pipeline_tools.py

